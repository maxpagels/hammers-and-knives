# Bayes' theorem
The probability that event A will occur given that even B has occured.

# Bayesian probability (subjective probability)
A probability relating to hypotheses as opposed probabilities derived from numeric frequencies. Probabilities are set by the statistician, as opposed to calculated from data.

# Bayesian inference
A from of statistical inference where the probability of a hypothesis (or hypotheses) holding is adjusted as new evidence becomes available.

# Markov chain
A state machine where a transition from A to B happens based on a probability. Typically, Markov chains are memoryless (the probability distribution of possible next states are based solely on the current state). Markov chains where state transitions are based on m past states are called m-order Markov chains (or Markov chains with memory m).

# Markov property
The Markov property is fulfilled iff the process in question is memoryless (see Markov chain).

# Statistical inference
Deducing properties of a population or underlying distribution by analysing data.